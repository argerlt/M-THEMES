Development of M-THEMES Features Write Up
=========================================

Andrew Kingery
Mesoscale Mechanics and Microstructures Laboratory
The Ohio State University
Steve Niezgoda, Austin Gerlt
November 2021


## Introduction

    This writeup is concerned with the development work on the M-THEMES (Mesoscale Thermomechanical Materials Simulator) simulation software used in the Mesoscale Mechanics and Microstructures Laboratory (MESO Lab) at The Ohio State University (OSU) that I, Andrew Kingery, completed during my time as an intern (roughly from January to December of 2021). When I began the software was called FORGE (Fourier Optimized Recrystallization and Grain Evolution), but that name was temporary, and was updated. The software is written in C++ (although the source code files all have the “.c” file extension, which is technically inaccurate), and is organized for parallel processing with the MPICH message passing library. The code uses the FFTW library, and the current version found in this repository uses FFTW 2, which I’m told is extremely outdated. Efforts were made to update the program to FFTW 3, but these changes have not been added to this specific repository.
    My goal at the start of my internship was to learn how the Hierarchical Data Format (HDF) worked, learn to use it, and write code so that M-THEMES could take in data on a given microstructure through an HDF (“.h5”) file. Originally the software took in microstructure data in a specially organized text file, which was inefficient for a number of reasons, and was clunky which made the workflow surrounding M-THEMES more difficult than it needed to be. I succeeded in writing code so that M-THEMES could take in an HDF file containing microstructure data. The “HDF Input” section of this writeup contains details on how I went about this, and some of the major problems that I encountered in the case that someone needs to go through this process again.
    Once M-THEMES could take in an HDF file as microstructure input, the next task was to add functionality for outputting the data into HDF files as well. Similarly, details on this procedure are laid out in the “HDF Output” section of this writeup, which again contains some of the problems that I encountered. Overall, I was able to successfully modify the code so that it could output data in an HDF file instead of the odd binary formatted files it was outputting before. The output now contains a structure, and should be much easier to use.
    Finally, after M-THEMES could both take in an HDF file containing microstructure and output the results of the simulation to an HDF file, my job was to attempt to port M-THEMES into a system that made accessing it easier to the general public. I attempted two ways in which to do this, and unfortunately failed in both of them. If I had more time interning here perhaps the results would be different, but as it stands the only way that I know for sure to interact with M-THEMES is to clone this repository, install the dependencies, compile M-THEMES, and run the binary with `mpiexec`. The two ways I attempted to make M-THEMES easier to use were to a) port M-THEMES to a DREAM.3D “filter” and b) port M-THEMES to a tool hosted on Purdue University’s nanohub hosting service. Again, unfortunately, I failed in both, but nonetheless the processes and struggles I went through are documented in the “DREAM.3D Filter Attempt” and the “NanoHub Tool Attempt” sections of this writeup. For those looking through those sections either to gleam information on my struggles or to attempt to successfully do either of the things I tried to do, it’s likely important to consider that my internship was a part-time internship done by a high school student, and someone with more experience could probably do a better job than I. 
    To make the documentation of my work complete, beneath most of the sections there is a resources section. This section contains relevant links for each project that I attempted, and hopefully these will be of use to anyone attempting to either replicate the work I did or do similar work on another project. This document is dual-purpose, attempting to both document my work and make the work that anyone else tries to start easier, so these links should be a good jumping off point.

## Current State of M-THEMES

### Dependencies

As the repository currently stands, M-THEMES requires three dependencies which are included in the root directory. These are MPICH for parallel processing through message passing, FFTW for fast fourier calculations, and HDF5 for HDF input and output. As mentioned in the introduction, the version of FFTW in use is FFTW 2, which is outdated. Not only does this mean that FFTW 2 must then be compiled from source in order to compile M-THEMES (since any modern package manager’s repositories don’t support FFTW 2 anymore), but that an older version of MPICH must be compiled and used as well. This makes packaging M-THEMES into an easy to install or use format difficult.
The HDF5 library that M-THEMES requires must be compiled with parallel support, which is why it’s included in the repository and why, during development, I was using a version that I compiled myself. Most modern repositories, notably including `apt`, have a parallel hdf library already packaged (the package in the apt repos is called `libhdf5-mpich`), so theoretically it wouldn’t be necessary to compile HDF from source in the future. I was concerned about compatibility with the old version of MPICH during development, and so I compiled it myself.
There was an attempt to automate the compilation and installation of all three dependencies with the `install.sh` shell script located in the root of the repository, and for the most part the script works, although it’s relatively impossible to write a simple installation script that will work on all linux environments that M-THEMES might be deployed to. The script is very easy to read, however, so if it breaks it should be relatively easy to troubleshoot.

### Organization

    When I first started looking at M-THEMES it was quite daunting to understand how the codebase was organized, so I will attempt to quickly document it here as either a jumping off point for new developers if one is brought in or a quick refresher to anyone coming back to M-THEMES after a hiatus. The code is mostly in C, although parts of it are written in C++ and therefore the Makefile compiles the software with `g++`. The program’s `main()` function is found in `evp.c`, which is the entrypoint for the binary executable. `evp.c` is pretty simple to understand, and just seems to set up the MPI environment, run a setup function, the actual evolution function, a cleanup function, and then cleans up the MPI environment.
    It’s important to note that, unlike most of the C/C++ projects that I have seen before, M-THEMES does not have header files for each individual C source file. Instead, essentially all of the function headers are stored in the `evp.h` file, which also contains constants and macro declarations. When adding features to M-THEMES I decided to follow this convention instead of making my own header files, since I figured that would be easier than trying to understand why such a decision was made or how I would go about changing it.
    The biggest function, and the one I presume does the most work for actual simulation, is the `Evolution()` function found in `src/evolution.c`. The `Evolution()` function is 1184 lines long, and large swaths of it are commented out with no comment explaining why, so it’s actual functionality is difficult to determine (especially for someone with as little Material Science experience as I have). If code cleanup methods are ever to be taken on, this function would arguably need the most work. Essentially all of the calls to other methods are done from `Evolution()`, sometimes in a loop, sometimes not, so if development is being done to add more features to the software the developer will need to determine where in the function is best to add the call, since there are several places it could be.
    Although that’s not a lot of information on the code structure, it’s essentially all that I needed to be able to begin development into M-THEMES, so hopefully it’s a good starting point. The only major changes that I made to the organization was the addition of the `hdf_output.c` file to handle HDF output code, so as not to overwhelm the `io.c` file which despite its name appears to only control output code.

### Resources

<https://github.com/mesoOSU/M-THEMES>

## HDF Input

When modifying M-THEMES to take in HDF input, most of the work that I did was in the `init.c` file, particularly in the `InitMicroStruct()` function. Why the function for reading in data from the microstructure file is in a file meant for initialization is beyond me, but nonetheless when I began working on the project that is where M-THEMES took in data about a microstructure from an ASCII text file, formatted in a specific manner.
In order to best describe how I went about writing the HDF input system in M-THEMES it is probably useful to quickly describe the input system that I was replacing so that the logic can be seen in the specific design decisions that I made. Previous to my internship, M-THEMES took in information about a microstructure that it was to perform simulations on in a text-formatted file, with each line containing 3 euler angles (floating point numbers), 3 coordinates (integers representing X, Y, and Z), a phase id (integer), and a grain id (integer). The file had essentially 3 nested for loops (although since those for loops are used so often they have been condensed into a macro called `local_loop`, even though this makes the code harder to read for a newcomer) that iterated over the lines in the file and stored the data to be used later in the simulation.
Before I review the code, I would like to describe in general how the new HDF system was designed and the reasoning behind some of the design decisions that I made. I wanted the new system to be as generalized as I could make it, which meant that I would need to modify M-THEMES other input functionality (that being reading the `input.in` file that’s passed into the program with information about the simulation) to accept not only the filepath of the HDF file itself but also dataset paths _within_ the HDF file for a Euler Angle dataset, a Phase ID dataset, and a Grain ID dataset. Since HDF already stores data in a multidimensional fashion, it wasn’t necessary to keep the x, y, and z coordinates that existed in the original text file (and looking at the code, it appears that those were only used to check and make sure a line wasn’t missing). This saves on space, and makes the data cleaner to look at. The Euler Angle dataset that M-THEMES now expects is a 4-dimensional dataset of doubles. Originally there were three 3-dimensional Euler Angle datasets, one for phi, theta, and omega, but this was changed to a single 4-dimensional dataset because that is what DREAM.3D outputs when it creates a synthetic microstructure file. In order to make that pipeline as easy as possible, M-THEMES was changed to accept a 4-dimensional Euler Angle dataset (so three dimensions for coordinates, and the final one that’s either 0, 1, or 2 for the specific angle). The Phase ID and Grain ID datasets are considerably simpler, each being a 3-dimensional dataset containing integers. Now that the general design of the program has been described, I can review the code that I actually wrote in case you’re reading this and wish to write something similar.
The new additions were done using the HDF5 C API. HDF does technically have a C++ interface, but this doesn’t support parallel processing with MPI, so since C++ can run any valid C code, the C API was used. Most of the additions that I made can be seen from lines 249-300 in `init.c`, right before the `local_loop` in `InitMicroStruct()`. I’ve tried to comment out the blocks of code by what their purpose is, but in case it’s unclear I’ll attempt to describe what I added in this space.
First, every item that HDF deals with needs to be initialized as an `hid_t` variable. `hid_t` seems to be a sort of strange way that HDF gets some unique behavior, but for my purposes it wasn’t really necessary to understand, I just needed to declare every ID for the file, each dataset, each dataspace, and each memory space as an `hid_t`. 
It’s worth noting that at this point we need to open the file, which means we need to take a string from the input.in file that’s passed into M-THEMES with the filepath to open. This already existed for the file input since M-THEMES also needed a filepath for the text file, but I added on to that system to add fields for the dataset paths for the Euler Angles, the Phase ID, and the Grain ID. Most of those changes were made in `io.c` (with some in `evp.h` to define the global variables), and were mostly easy to complete. I simply followed the pattern that was laid out in both of those files for all of the other fields to add a couple more.
Going back to `init.c`, this is the point where I open the file with `H5Fopen()`, passing in `H5F_ACC_RDONLY` to make the file read only, which is what we want. Then, I open all of the datasets with `H5Dopen2()`. Opening the datasets doesn’t actually move the data anywhere in memory, but it allows us to get a handle on the dataset and assign it to a variable. The function needs the file ID that we got from opening the file earlier, as well as the path within the file (remember HDF is a hierarchical data format, so it has its own pseudo-filesystem to navigate, which is what this path is). Finally, the function takes `H5P_DEFAULT` to set the “access properties”. Essentially this means that we’re not doing anything nonstandard, we just want to read in the data.
If M-THEMES were running without MPI at all, and the code was just being run as a single executable, it would now be the point to read in the data. However, this is not the case. Since M-THEMES is designed to be split into subprocesses that each run the same code, we need to make sure that each one gets a corresponding section (or “hyperslab”) of the data. Back in the text-based system, this was done by calculating a starting point for the subprocess, and iterating over the file until it was in position. That’s not very efficient, and there are better ways to do it with HDF. In the resources below there is a page titled “Reading From or Writing To a Subset of a Dataset”, which was extensively helpful for this step. Essentially, HDF has the capability to break up a dataset into a smaller subset, which can then be used in place of the original dataset when being read. This means that there’s nothing that’s read from the file and wasted, as the dataset is prepared beforehand before it is read to maximize efficiency. 
In order to do this hyper slabbing, we need to do several things: 1) open the dataspace of all of the datasets, which tells information about the shape of the data, 2) calculate the size of the hyperslab, 3) select the hyperslabs within the dataspace, 4) define a memory dataspace that mirrors the size and dimensions of the hyperslab, 5) allocate space in memory to hold the dataspace in, and finally 6) read in the data.
That’s a lot of steps, but each one can be done relatively straightforwardly with the HDF API. The trickiest part of all of this to understand was the memory dataspace, which wasn’t something that I realized I needed until very late. From what I can gather, the memory space is necessary because when the dataset is being read, you can pass two dataspaces into it, one to restrict the dataset in memory, and one to restrict the dataset being read in the file. We don’t want to restrict the dataset in memory, because we want the entirety of the hyperslab to be read into memory. So, we create a memory space that’s designed to fit an entire hyperslab.
Finally, after the hyperslabs have been selected and read in (to arrays that were allocated to be the right size with `malloc`), all of the `hid_t`s are closed with their respective closing function. The only tricky thing that I had to do was some pointer arithmetic within the `local_loop` itself. Because I am reading in all of the data before processing it, everything is stored in a single array by the time we come to the `local_loop`. Unfortunately you can’t generate a multi-dimensional array and pass that into the HDF API to read in data, something about the memory position gets screwed up, so when accessing elements we have to do pointer arithmetic (currently on lines 305-310). In order to understand how the pointer arithmetic works it’s necessary to understand how the data is moved from a hyperslab to a linear set of memory, but essentially each coordinate is multiplied by the dimensions of the subarrays after it, then those are all summed to get the distance from the starting location in memory to the desired location. We then add the pointer for the data array, so that the resulting memory address is the desired element, and finally dereference the pointer with the `*` operator so that we can store the actual double/integer. This does make the code harder to read (it’s much easier to understand `euler_data[px][py][px][0]` than it is to understand `*(euler_data + px*CellDim[1]*CellDim[2]*3 + py*CellDim[2]*3 + pz*3 + 0)`), but in the end they both do the same thing and this is the only way I could find to get it to work.
That’s pretty much all that I did in order for M-THEMES to be able to read an HDF file, and all in all looking back it seems simpler than it did while I was writing it. The only final thing that I did was to free the allocated arrays once the `local_loop` was done with them, since they aren’t used anywhere else and it would be a _huge_ memory leak to not free them.

### Resources

<https://confluence.hdfgroup.org/display/HDF5/Introduction+to+HDF5>
<https://confluence.hdfgroup.org/display/HDF5/Learning+the+Basics>
<https://confluence.hdfgroup.org/display/HDF5/Reading+From+or+Writing+To+a+Subset+of+a+Dataset>


## HDF Output

    When adding HDF output support, I decided on making a new file instead of adding functions to the `io.c` file, which primarily deals with the current MPI-based output solution. The new `hdf_output.c` file is the only new file that I added, and it does in fact only contain C code, so the file extension is fine in my book. The old output system used MPI’s binary file writing API to write to several binary files that weren’t very organized, so the challenge of the new system was to combine all of these output files into one HDF file that was more organized, and easier to read. In order to leverage the MPI system that M-THEMES runs inside, the HDF API needs to be compiled with parallel support in order to support parallel creation on a HDF file. This makes the dependencies slightly more complicated, though if the other dependency issues were solves (primarily those with FFTW 2), then it would be trivial to get the parallel library installed (apt calles the package `libhdf5-mpich`, as mentioned in the “Current State of M-THEMES > Dependencies'' section of this document). Writing the output system was actually somewhat simpler than writing the input system, and I’ll detail the process that I went through to complete that.
    In the `io.c` file, there are many functions that each output a single MPI binary file. These functions were called from the ending portion of the `Evolution()` function in `evolution.c`, with some being commented out, presumably to restrict functionality for a certain simulation. When writing the HDF output, I basically copied each of these functions into the new `hdf_output.c` and changed all of the MPI API calls to similar HDF ones. That way, I could be sure that all of the math used to create the output files was the same, and the new HDF file would contain the same data originally found in the binary output files. 
The HDF parallel API can be a little verbose when creating an HDF file, so I abstracted all of that code to a helper function called `WriteHDFDataset()`, which attempts to generify the parallel dataset creation and writing process by taking in a parallel file id, a number of dimensions, a path in which to put the dataset, a type id, and a buffer containing the actual data to write. Within this function, similar operations are performed as were done in the input code. In order to create a parallel dataset, it’s necessary to first define a hyperslab that blocks out the actual section of the total dataset that is about to be written. Similar to the input code, we also need to create a dataspace in memory to hold the data that we’re about to write to ensure that the map from memory to disk is how we want it to be. The actual dataspace and dataset creation are pretty standard for HDF, but before we write any data we define a transfer property with `H5Pset_dxpl_mpio(xf_id, H5FD_MPIO_COLLECTIVE);`, which sets `xf_id` to allow parallel communication. That `xf_id` is then used in the final call to `H5DWrite()`, which does the actual writing of the data. After that, the newly created dataspace, memory dataspace, and dataset are closed to prevent a memory leak (although the file is kept open since we know it was created one layer above this file, and should be closed there). 
Also of note is the creation of the parallel HDF file, although this is significantly simpler (and less lines of code) than the creation and writing of a given parallel dataset. Even so, I still separated the creation of the parallel file into another function, called `CreateParallelHDF()`, since it was an action I repeated a lot and didn’t want to retype every time.
Once I had gotten every file to output it’s own respective HDF file, I began the work of combining them into one. Essentially it’s useless to have many related HDF files all sitting in the same directory because you can organize things within the HDF directory, so I had to change the implementation a little bit. Most output functions are writing more than one dataset (usually 6, for some scientific reason that has been explained to me but I didn’t really understand), so those functions actually create a group (which can be thought of like a directory) to put all 6 of those datasets inside. This keeps things much more organized. Each function no longer created its own file, but was passed a file in to do work within. This meant that the file had to be created somewhere else, which is in `evolution.c`. That way, only one output file is created in the entire project, and each function just appends the data needed into it.
The last thing I want to mention is how I handled functions like WriteTextureHDF. The texture output is supposed to contain multiple things, including all 3 euler angles, a phase id, and a grain id for each voxel in the microstructure. In order to wrap all of those 3 together in previous versions of the code, M-THEMES created a custom datatype to write to the output file. This meant that in order to be read, the file had to be passed through another separate program that also understood that custom datatype and converted that file to useful output. Instead of doing that (although custom data types are a thing in HDF), I just created multiple datasets in a group each containing the euler angles, phase id, and grain id, just like it’s formatted in the input file. 

### Resources

<https://portal.hdfgroup.org/display/HDF5/Parallel+HDF5>
<https://confluence.hdfgroup.org/display/HDF5/Introduction+to+Parallel+HDF5>
<https://portal.hdfgroup.org/display/knowledge/Parallel+HDF5>

## DREAM.3D Filter Attempt

    Once M-THEMES was at a point that it had both HDF input and output capabilities, my attention was turned from adding new features to M-THEMES toward packaging M-THEMES to make it much easier to use. The first attempt at doing this was to port M-THEMES to a DREAM.3D filter, so that it would simply sit inside the DREAM.3D pipeline and would save a lot of time. Unfortunately I did not get very far in this attempt.
    My problems with porting M-THEMES to a DREAM.3D filter mostly came from being unable to successfully set up the required DREAM.3D development environment on my computer. Admittedly, my environment is quite different from the development environment of others, because I run Linux and not Windows. Most of the time this makes development much easier, but it appears in the case of DREAM.3D, most people do development on Windows and Linux support for the development environment, although existent, has been an afterthought. In order to develop a DREAM.3D filter, the development system needs to be set up with the DREAM.3D SDK, and a compiled version of DREAM.3D. I attempted to follow the instructions to build the DREAM.3D SDK on linux, but I was unable to get the SDK’s make system to complete successfully. DREAM.3D does in fact provide an alternative in the case that doesn’t work, that being the `ninja` build system, but I was unable to get that to work either. Ultimately I think that making M-THEMES into a DREAM.3D filter is probably still very possible, if someone can actually get the development environment to work correctly, although I have concerns with the current dependency system and how such a thing would be integrated into DREAM.3D.

### Resources

<http://www.dream3d.io/6_Developer/CreatingAFilter/>
<http://www.dream3d.io/6_Developer/WritingAFilter/>
<http://www.dream3d.io/6_Developer/Linux_Configuring_and_Building_DREAM3D/>
<https://github.com/bluequartzsoftware/DREAM3DSuperbuild/blob/develop/docs/Making_an_SDK_Linux.md>

## NanoHub Tool Attempt

After failing to be able to port M-THEMES to a DREAM.3D filter, my job was shifted to explore the possibility of making M-THEMES into a NanoHub tool. NanoHub is an online simulations tool hosting platform made and supported by Purdue University, and would be an ideal candidate for getting M-THEMES out into people’s hands. Unfortunately, as will the DREAM.3D project, I was unable to complete this task, although porting NanoHub to M-THEMES does seem more promising to me than porting it to DREAM.3D, at least at the moment. My process and struggles for creating a NanoHub tool are what follow.
To begin, I went through NanoHub’s tool generation process. That included making a NanoHub account, which NanoHub recommends doing when doing developer work so that username and password can be used for authentication if the developer ever uses the provided “workspace” tool, which I never did.
The next step after account creation was to decide which “Tool Publishing” option I would follow for M-THEMES. As NanoHub is a graphical system, I would need to wrap M-THEMES in some sort of rudimentary GUI so that a user could interact with it through a web browser. Obviously at the moment M-THEMES is strictly a command line program, so this presented a challenge. NanoHub supports multiple different kinds of GUI applications, though, including: SimTools, Rappture, Jupyter Notebook, Rappture + Jupyter, SimTool + Jupyter, or simply a pre-existing X11 GUI. NanoHub’s [“Why Publish?”](https://nanohub.org/whypublish) page details these different options, and explains reasons for choosing one over choosing another. Of all of the options available I ended up choosing the Rappture option.
I chose Rappture for several reasons, but chief among them is that Rappture supports automatic (or, well, simplified may be a better word but NanoHub refers to it as automatic) GUI creation capabilities. Interestingly, Rappture was actually created by NanoHub itself as a way to wrap around and communicate with command line softwares like M-THEMES. When following NanoHub’s handy flowchart that appears on the [“Why Publish?”](https://nanohub.org/whypublish) page, I got Rappture as well, and was satisfied that it would probably work well considering it fell under the “My code is computationally intensive” section of the flowchart, and I wasn’t sure whether M-THEMES was considered computationally intensive or not. The final reason that I chose Rappture as the “Tool Publishing” option was that it seemed the simplest out of any of the options. Rappture works by creating a GUI based on an XML file that specifies inputs and outputs to a program, and that meant that I didn’t have to deal with figuring out how to fit M-THEMES into a Jupyter Notebook or work with a tool that required a lot of expertise.
Unfortunately, though, my struggles with Rappture started pretty immediately. The largest reason that I was unable to get Rappture to work is that the software hasn’t been supported in several years. As of the time of writing (November 2021), the last official stable build of Rappture was released in September of 2013, and the last “nightly” unstable build was released in August of 2016. I attempted to use both of these releases, but unfortunately was unable to get either one to work completely. The download page for Rappture contains tarballs with precompiled binaries to run on given XML files, which internally contain GUI elements and how they relate to another program that is run upon execution. I was actually able to get the 2013 precompiled version to run on my linux machine, but unfortunately due to it being compiled over 8 years ago, I ran into a lot of problems with the binary expecting certain versions of standard libraries that I did not have. In order to get the binary to even run, I had to spend a while symlinking libraries in the `/usr/lib` directory to trick the binary into thinking that I had a different version number, even though the object files were just symlinks to more recent versions. Eventually I was able to execute the binary and open some of the examples that were provided, but upon actually attempting to run a simulation, most of the time the process failed and I was given an error specifically about the version of OpenSSL that I was running. Not wanting to downgrade my system-wide OpenSSL to an old (and insecure) version, I decided to try the 2016 binary.
The 2016 precompiled binary had much of the same problems, expecting versions of standard libraries that I didn’t have. Much more symlinks in `/usr/lib` later, I eventually realized that I wouldn’t even be able to get this binary version to run, running into problems with libvtk 9.0 not being able to work with a program that expected libvtk 6.0. With more time and effort it would probably be possible to construct an operating system with exactly the libraries that Rappture needs to run properly, but I decided that it wasn’t worth it at this point since the dependencies are extremely outdated, and will continue to grow even more out of date.
As a last ditch effort, I located the actual source code releases (again a stable version from 2013 and an unstable one from 2016) and attempted to compile both of them myself, in case they would recognize the library versions that I was running and could actually run an example simulation. Compiling Rappture from source involves two different sets of source code, one for the source and one for the runtime. The compilation process is a bit strange but well documented enough, all that needs done is for both the source and runtime tarballs to be extracted in the same directory, and a compilation script inside the runtime directory needs to be run. Internally the script looked complicated so I didn’t get very far in deciphering it, but it was well commented and seemed to use the standard configure, make, and make install process, albeit with some special considerations. Unfortunately, both the stable and unstable versions of Rappture errored out during compilation. Both of them did pass the configure script section, which I assume would have resolved the library issues, but I was unable to fully compile either one. The unstable (2013) version of the source code had errors in which it attempted to create new directories, but couldn’t because earlier in the process it had made executable files there. I tried to manually intervene, even going as far as to change one of the makefiles so that any time it tried to create that directory it would delete whatever was there before it, but the problems compounded and there seems to be something wrong with the way the compilation script is set up. After fighting with that for a while, I tried to move on to the unstable nightly source code (2016), and had much more luck. I was in fact able to get it to the point that it was actually running a compiler and began compiling the source code, but the actual provided source code was unable to compile. To me, this shows that the versions of Rappture that are currently available are both too outdated and too unstable to be able to develop with. It was at this point that my internship was winding down, so I was unable to press on further.
If I had more time in this internship, and if you’re reading to continue my work, I would probably try another option besides Rappture to construct a GUI, or get in touch with NanoHub itself since they’re the ones who are supposed to be supporting it. The tool seems really promising, but being unable to actually get it to run any of the examples that it’s supposed to run meant that I didn’t get very far. Beyond actually getting it to work, there is still the task of reprogramming M-THEMES’ input system to use the Rappture C API in order to be able to transfer data properly, and I’m still not entirely convinced that Rappture actually supports file uploading, which would be an absolute must for the kind of work that M-THEMES is doing (unless you want a user to type in the euler angles, phase ids, and grain ids of every voxel in a microstructure they’re trying to work with). 

### Resources

<https://nanohub.org/whypublish>
<https://nanohub.org/whypublish/whypublishhowtostart>
<https://nanohub.org/whypublish/whypublishdeployrappture> - How to deploy rappture tool
<https://nanohub.org/infrastructure/rappture/wiki/Documentation> - Rappture docs
<https://nanohub.org/resources/14671> - Rappture bootcamp videos
